{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GATLayerWithIRCRWR(nn.Module):\n",
    "    nodes_dim = 0      # node dimension\n",
    "    head_dim = 1       # attention head dim\n",
    "\n",
    "    def __init__(self, num_in_features, num_out_features, num_of_heads, gamma=0.7, beta=0.5, concat=True, activation=nn.ELU(),\n",
    "                 dropout_prob=0.6, random_walk_with_restart=True, add_residual_connection=True, add_skip_connection=True, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_of_heads = num_of_heads\n",
    "        self.num_out_features = num_out_features\n",
    "        self.concat = concat  # whether we should concatenate or average the attention heads\n",
    "        self.residual_connection = add_residual_connection\n",
    "        self.random_walk_with_restart = random_walk_with_restart\n",
    "        self.add_skip_connection = add_skip_connection\n",
    "        self.gamma = gamma # RWR의 재시작 확률\n",
    "        self.beta = beta # residual connection의 가중치\n",
    "\n",
    "        #\n",
    "        # Trainable weights: linear projection matrix (denoted as \"W\" in the paper), attention target/source\n",
    "        # (denoted as \"a\" in the paper) and bias (not mentioned in the paper but present in the official GAT repo)\n",
    "        #\n",
    "\n",
    "        # You can treat this one matrix as num_of_heads independent W matrices\n",
    "        self.linear_proj = nn.Linear(num_in_features, num_of_heads * num_out_features, bias=False)\n",
    "\n",
    "        # After we concatenate target node (node i) and source node (node j) we apply the \"additive\" scoring function\n",
    "        # which gives us un-normalized score \"e\". Here we split the \"a\" vector - but the semantics remain the same.\n",
    "        # Basically instead of doing [x, y] (concatenation, x/y are node feature vectors) and dot product with \"a\"\n",
    "        # we instead do a dot product between x and \"a_left\" and y and \"a_right\" and we sum them up\n",
    "        # 즉 논문에서의 e_ij = LeakyReLU(a_T[ Wh_i ∣∣ Wh_j ])를 연산량을 줄이기 위해\n",
    "        # e_ij​ = LeakyReLU((Wh_i​)⋅a_left​ + (Wh_j)⋅a_right​)로 바꿔 수행한다.\n",
    "        self.scoring_fn_target = nn.Parameter(torch.Tensor(1, num_of_heads, num_out_features))\n",
    "        self.scoring_fn_source = nn.Parameter(torch.Tensor(1, num_of_heads, num_out_features))\n",
    "\n",
    "        # Bias is definitely not crucial to GAT - feel free to experiment (I pinged the main author, Petar, on this one)\n",
    "        if bias and concat:\n",
    "            self.bias = nn.Parameter(torch.Tensor(num_of_heads * num_out_features))\n",
    "        elif bias and not concat:\n",
    "            self.bias = nn.Parameter(torch.Tensor(num_out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        if self.random_walk_with_restart:\n",
    "            self.W_random_walk = nn.Linear(num_in_features, num_of_heads * num_out_features, bias=False)\n",
    "        else:\n",
    "            self.register_parameter('W_random_walk', None)\n",
    "\n",
    "        if self.residual_connection:\n",
    "            self.W_residual = nn.Linear(num_in_features, num_of_heads * num_out_features, bias=False)\n",
    "        else:\n",
    "            self.register_parameter('W_residual', None)\n",
    "\n",
    "        if add_skip_connection and not (add_residual_connection or random_walk_with_restart):\n",
    "            self.skip_proj = nn.Linear(num_in_features, num_of_heads * num_out_features, bias=False)\n",
    "        else:\n",
    "            self.register_parameter('skip_proj', None)\n",
    "\n",
    "        #\n",
    "        # End of trainable weights\n",
    "        #\n",
    "\n",
    "        self.leakyReLU = nn.LeakyReLU(0.2)  # using 0.2 as in the paper, no need to expose every setting\n",
    "        self.activation = activation\n",
    "        # Probably not the nicest design but I use the same module in 3 locations, before/after features projection\n",
    "        # and for attention coefficients. Functionality-wise it's the same as using independent modules.\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "\n",
    "        self.reset_parameter()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        #\n",
    "        # Linear Projection\n",
    "        #\n",
    "\n",
    "        in_nodes_features, edge_index, initial_features_for_random_walk, initial_features_for_residual_connection = data  # unpack data\n",
    "\n",
    "        # Save the initial features for random walk\n",
    "        if initial_features_for_random_walk is None and self.random_walk_with_restart:\n",
    "            initial_features_for_random_walk = self.W_random_walk(in_nodes_features).reshape(-1, self.num_of_heads, self.num_out_features)\n",
    "        \n",
    "        # Save the initial features for residual connection\n",
    "        if initial_features_for_residual_connection is None and self.residual_connection:\n",
    "            initial_features_for_residual_connection = self.W_residual(in_nodes_features).reshape(-1, self.num_of_heads, self.num_out_features)\n",
    "\n",
    "        num_of_nodes = in_nodes_features.shape[self.nodes_dim]\n",
    "        assert edge_index.shape[0] == 2, f'Expected edge index with shape=(2,E) got {edge_index.shape}'\n",
    "\n",
    "        # shape = (노드 수, 입력 특징 수) : 각 노드의 입력 특징을 나타낸다.\n",
    "        # 논문에서와 같이 모든 입력 노드 특징에 dropout을 적용한다.\n",
    "        # Note: for Cora features are already super sparse so it's questionable how much this actually helps\n",
    "        in_nodes_features = self.dropout(in_nodes_features) # 공식 GAT 구현에서도 dropout을 사용.\n",
    "\n",
    "        # shape = (노드 수, 입력 특징 수) * (입력 특징 수, 헤드 수 * 출력 특징 수) -> (노드 수, 헤드 수, 출력 특징 수)\n",
    "        # We project the input node features into NH independent output features (one for each attention head)\n",
    "        # 즉 각 노드의 특징을 각 헤드마다 다른 특징으로 변환한다.\n",
    "        nodes_features_proj = self.linear_proj(in_nodes_features).reshape(-1, self.num_of_heads, self.num_out_features)\n",
    "\n",
    "        nodes_features_proj = self.dropout(nodes_features_proj) # 공식 GAT 구현에서도 dropout을 사용.\n",
    "\n",
    "        #\n",
    "        # Edge attention calculation\n",
    "        #\n",
    "\n",
    "        # Apply the scoring function (* represents element-wise (a.k.a. Hadamard) product)\n",
    "        # shape = (노드 수, 헤드 수, 출력 특징 수) * (1, 헤드 수, 출력 특징 수) -> (노드 수, 헤드 수, 1) -> (노드 수, 헤드 수)\n",
    "        # sum은 마지막 차원을 기준으로 sum하므로 (N, NH, FOUT) -> (N, NH) 즉, 노드 수 x 헤드 수\n",
    "        # 여기서 학습 가능한 파라미터인 scoring_fn_source, scoring_fn_target을 사용하여 각 노드의 특징을 계산한다.\n",
    "        # [GAT에선 a 벡터를 사용하여 두 노드의 특징을 결합한 후, scoring function을 통해 attention score를 계산한다.]\n",
    "        scores_source = (nodes_features_proj * self.scoring_fn_source).sum(dim=-1) # 마지막 차원을 기준으로 sum 즉, (N, NH, FOUT) -> (N, NH) 즉, 노드 수 x 헤드 수\n",
    "        scores_target = (nodes_features_proj * self.scoring_fn_target).sum(dim=-1) # (N, NH) 즉, 노드 수 x 헤드 수\n",
    "        \n",
    "        # We simply copy (lift) the scores for source/target nodes based on the edge index. Instead of preparing all\n",
    "        # the possible combinations of scores we just prepare those that will actually be used and those are defined\n",
    "        # by the edge index.\n",
    "        # scores shape = (E, NH), nodes_features_proj_lifted shape = (E, NH, FOUT), E - number of edges in the graph\n",
    "        # 각 엣지에 대한 source, target의 attention score를 계산한다.\n",
    "        scores_source_lifted, scores_target_lifted, nodes_features_proj_lifted = self.lift(scores_source, scores_target, nodes_features_proj, edge_index)\n",
    "        scores_per_edge = self.leakyReLU(scores_source_lifted + scores_target_lifted)\n",
    "\n",
    "        # shape = (엣지 수, 헤드 수, 1) -> (엣지 수, 헤드 수, 1) (unsqueeze를 통해 차원을 추가한다. 그래야 element-wise 곱을 할 수 있다.)\n",
    "        # 이제 softmax를 통해 attention coefficient를 계산한다.\n",
    "        attentions_per_edge = self.neighborhood_aware_softmax(scores_per_edge, edge_index[1], num_of_nodes)\n",
    "        # Add stochasticity to neighborhood aggregation\n",
    "        attentions_per_edge = self.dropout(attentions_per_edge)\n",
    "\n",
    "        #\n",
    "        # Neighborhood aggregation\n",
    "        #\n",
    "\n",
    "        # Element-wise (aka Hadamard) product. Operator * does the same thing as torch.mul\n",
    "        # shape = (엣지 수, 헤드 수, 출력 특징 수) * (엣지 수, 헤드 수, 1) -> (엣지 수, 헤드 수, 출력 특징 수) 1이 FOUT으로 브로드캐스팅된다.\n",
    "        # FOUT은 출력 특징 수이다. 즉, 각 엣지의 attention score를 이용하여 각 노드의 특징을 가중합하여 계산한다.\n",
    "        nodes_features_proj_lifted_weighted = nodes_features_proj_lifted * attentions_per_edge\n",
    "\n",
    "        # 이 부분은 각 노드의 이웃 노드의 특징을 가중합하여 계산한다.\n",
    "        # shape = (노드 수, 헤드 수, 출력 특징 수)\n",
    "        # Aggregate multi-head attentions and Random Walk with Restart (optional)\n",
    "        out_nodes_features = self.aggregate_neighbors(initial_features_for_random_walk, nodes_features_proj_lifted_weighted, edge_index, in_nodes_features, num_of_nodes)\n",
    "\n",
    "        #\n",
    "        # Skip connections (optional) and Initial Residual Connection (optional), concat and bias\n",
    "        #\n",
    "\n",
    "        out_nodes_features = self.skip_concat_bias(in_nodes_features, out_nodes_features, initial_features_for_residual_connection)\n",
    "\n",
    "        return (out_nodes_features, edge_index, initial_features_for_random_walk, initial_features_for_residual_connection)\n",
    "    \n",
    "    def reset_parameter(self):\n",
    "        \"\"\"\n",
    "        원래 논문에서 GAT을 구현한 코드가 TensorFlow로 되어있고, 그 코드에서는 기본 초기화 방법으로 사용했기 때문에\n",
    "        Glorot (Xavier uniform) initialization을 사용한다.\n",
    "        \n",
    "        Tensorflow의 기본 초기화 방법은 Glorot (Xavier uniform) initialization이다.\n",
    "        https://stackoverflow.com/questions/37350131/what-is-the-default-variable-initializer-in-tensorflow\n",
    "\n",
    "        \"\"\"\n",
    "        nn.init.xavier_uniform_(self.linear_proj.weight)\n",
    "        nn.init.xavier_uniform_(self.scoring_fn_target)\n",
    "        nn.init.xavier_uniform_(self.scoring_fn_source)\n",
    "        if self.random_walk_with_restart:\n",
    "            nn.init.xavier_uniform_(self.W_random_walk.weight)\n",
    "        if self.residual_connection:\n",
    "            nn.init.xavier_uniform_(self.W_residual.weight)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            torch.nn.init.zeros_(self.bias)\n",
    "\n",
    "    def lift(self, scores_source, scores_target, nodes_features_matrix_proj, edge_index):\n",
    "        \"\"\"\n",
    "        Lifts i.e. duplicates certain vectors depending on the edge index.\n",
    "        One of the tensor dims goes from N -> E (that's where the \"lift\" comes from).\n",
    "        즉 lifts는 edge index에 따라 특정 벡터를 엣지 수만큼 복제한다.\n",
    "        텐서의 차원 중 하나가 N -> E로 변한다.\n",
    "        여기서 N은 노드 수, E는 엣지 수이다.\n",
    "\n",
    "        \"\"\"\n",
    "        # src_nodes_index :  tensor([   0,    0,    0,  ..., 2707, 2707, 2707])\n",
    "        # trg_nodes_index :  tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706])\n",
    "        src_nodes_index = edge_index[0]\n",
    "        trg_nodes_index = edge_index[1]\n",
    "\n",
    "        # scores_source shape before :  torch.Size([2708, 8])\n",
    "        scores_source = scores_source.index_select(self.nodes_dim, src_nodes_index)\n",
    "        # scores_source shape after :  torch.Size([10556, 8])\n",
    "        scores_target = scores_target.index_select(self.nodes_dim, trg_nodes_index)\n",
    "        # nodes_features_proj shape torch.Size([2708, 8, 8])\n",
    "        nodes_features_matrix_proj_lifted = nodes_features_matrix_proj.index_select(self.nodes_dim, src_nodes_index)\n",
    "        # nodes_features_matrix_proj_lifted shape :  torch.Size([10556, 8, 8])\n",
    "\n",
    "        return scores_source, scores_target, nodes_features_matrix_proj_lifted\n",
    "\n",
    "    def neighborhood_aware_softmax(self, scores_per_edge, trg_index, num_of_nodes):\n",
    "        \"\"\"\n",
    "        이웃 노드들의 attention score를 softmax를 통해 계산한다.\n",
    "        \"\"\"\n",
    "\n",
    "        # Calculate the numerator. Make logits <= 0 so that e^logit <= 1 (this will improve the numerical stability)\n",
    "        # https://stats.stackexchange.com/questions/338285/how-does-the-subtraction-of-the-logit-maximum-improve-learning\n",
    "        scores_per_edge = scores_per_edge - scores_per_edge.max()\n",
    "        exp_scores_per_edge = scores_per_edge.exp()\n",
    "\n",
    "        # Calculate the denominator. shape = (E, NH)\n",
    "        neigborhood_aware_denominator = self.sum_edge_scores_neighborhood_aware(exp_scores_per_edge, trg_index, num_of_nodes)\n",
    "\n",
    "        # 1e-16은 이론적으로 필요하지 않지만 수치적 안정성을 위해 (0으로 나누는 것을 피하기 위해) 추가했다.\n",
    "        attentions_per_edge = exp_scores_per_edge / (neigborhood_aware_denominator + 1e-16)\n",
    "        # shape = (E, NH) -> (E, NH, 1)로 만들어서 projected node features와 element-wise 곱을 할 수 있게 한다.\n",
    "\n",
    "        return attentions_per_edge.unsqueeze(-1)\n",
    "    \n",
    "    def sum_edge_scores_neighborhood_aware(self, exp_scores_per_edge, trg_index, num_of_nodes):\n",
    "        # attention head 개수만큼 브로드캐스팅한다. 여기서 브로드캐스팅이란 차원을 늘려서 연산을 수행하는 것을 의미한다.\n",
    "        # E -> (E, NH)\n",
    "        trg_index_broadcasted = self.explicit_broadcast(trg_index, exp_scores_per_edge)\n",
    "\n",
    "        # shape = (N, NH)\n",
    "        size = list(exp_scores_per_edge.shape)  # convert to list otherwise assignment is not possible\n",
    "        size[self.nodes_dim] = num_of_nodes\n",
    "        neighborhood_sums = torch.zeros(size, dtype=exp_scores_per_edge.dtype, device=exp_scores_per_edge.device)\n",
    "\n",
    "        # exp_scores_per_edge를 trg_index_broadcasted의 값을 index로 사용하여 neighborhood_sums에 더한다.\n",
    "        # 그렇게 되면 각 노드의 이웃 노드들의 attention score의 합을 계산할 수 있다.\n",
    "        neighborhood_sums.scatter_add_(self.nodes_dim, trg_index_broadcasted, exp_scores_per_edge)\n",
    "\n",
    "        # edge_index의 차원에 맞게 브로드캐스팅한다.\n",
    "        # 모든 location의 값이 i번째 노드의 attention score의 합으로 브로드캐스팅되는 것이다.\n",
    "        # shape = (N, NH) -> (E, NH)\n",
    "        return neighborhood_sums.index_select(self.nodes_dim, trg_index)\n",
    "\n",
    "    def aggregate_neighbors(self, initial_features, nodes_features_proj_lifted_weighted, edge_index, in_nodes_features, num_of_nodes):\n",
    "        # shape = (E, NH, FOUT) -> (N, NH, FOUT)\n",
    "        out_nodes_features = torch.zeros(num_of_nodes, *nodes_features_proj_lifted_weighted.shape[1:], dtype=in_nodes_features.dtype, device=in_nodes_features.device)\n",
    "\n",
    "        # shape = (E) -> (E, NH, FOUT)\n",
    "        trg_index_broadcasted = self.explicit_broadcast(edge_index[1], nodes_features_proj_lifted_weighted)\n",
    "        # aggregation step - we accumulate projected, weighted node features for all the attention heads\n",
    "        # shape = (E, NH, FOUT) -> (N, NH, FOUT)\n",
    "        out_nodes_features.scatter_add_(self.nodes_dim, trg_index_broadcasted, nodes_features_proj_lifted_weighted)\n",
    "\n",
    "        # Random walk with Restart\n",
    "        if self.random_walk_with_restart:\n",
    "            out_nodes_features = (1 - self.gamma) * out_nodes_features + self.gamma * initial_features\n",
    "\n",
    "        return out_nodes_features\n",
    "\n",
    "    def explicit_broadcast(self, this, other):\n",
    "        # 차원이 같아질 때까지 singleton 차원을 추가한다.\n",
    "        for _ in range(this.dim(), other.dim()):\n",
    "            this = this.unsqueeze(-1) # 가장 마지막 차원을 추가한다.\n",
    "\n",
    "        # other 텐서와 같은 모양으로 확장하는데, 이 때 실제로 데이터를 복사하지는 않고, 필요에 따라 가상적으로 차원을 확장한다.\n",
    "        return this.expand_as(other)\n",
    "    \n",
    "    def skip_concat_bias(self, in_nodes_features, out_nodes_features, initial_features):\n",
    "        if self.add_skip_connection and not (self.residual_connection or self.random_walk_with_restart):  # add skip or residual connection\n",
    "            if out_nodes_features.shape[-1] == in_nodes_features.shape[-1]:  # if FIN == FOUT\n",
    "                # unsqueeze does this: (N, FIN) -> (N, 1, FIN), out features are (N, NH, FOUT) so 1 gets broadcast to NH\n",
    "                # thus we're basically copying input vectors NH times and adding to processed vectors\n",
    "                out_nodes_features += in_nodes_features.unsqueeze(1)\n",
    "            else:\n",
    "                # FIN != FOUT so we need to project input feature vectors into dimension that can be added to output\n",
    "                # feature vectors. skip_proj adds lots of additional capacity which may cause overfitting.\n",
    "                out_nodes_features += self.skip_proj(in_nodes_features).view(-1, self.num_of_heads, self.num_out_features)\n",
    "\n",
    "        if self.residual_connection:  # add residual connection\n",
    "            if out_nodes_features.shape[-1] == initial_features.shape[-1]:  # if FIN == FOUT\n",
    "                out_nodes_features += initial_features\n",
    "        if self.concat:\n",
    "            # shape = (N, NH, FOUT) -> (N, NH*FOUT)\n",
    "            out_nodes_features = out_nodes_features.reshape(-1, self.num_of_heads * self.num_out_features)\n",
    "        else:\n",
    "            # shape = (N, NH, FOUT) -> (N, FOUT)\n",
    "            out_nodes_features = out_nodes_features.mean(dim=self.head_dim)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out_nodes_features += self.bias\n",
    "\n",
    "        return out_nodes_features if self.activation is None else self.activation(out_nodes_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reference: GRAPH ATTENTION NETWORKS (2018).\n",
    "\n",
    "https://github.com/PetarV-/GAT\n",
    "https://github.com/gordicaleksa/pytorch-GAT\n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class GATWithIRCRWR(nn.Module):\n",
    "    def __init__(self, num_of_additional_layer, num_in_features, gamma, beta, random_walk_with_restart=True, add_residual_connection=True, bias=True, dropout=0.6):\n",
    "        super().__init__()\n",
    "\n",
    "        additional_layers = []\n",
    "\n",
    "        for _ in range(num_of_additional_layer):\n",
    "            additional_layers.append(\n",
    "                    GATLayerWithIRCRWR(\n",
    "                    num_in_features=8*8,  # consequence of concatenation\n",
    "                    num_out_features=8,\n",
    "                    num_of_heads=8,\n",
    "                    gamma=gamma,\n",
    "                    beta=beta,\n",
    "                    concat=True,\n",
    "                    activation=nn.ELU(),\n",
    "                    dropout_prob=dropout,\n",
    "                    random_walk_with_restart=random_walk_with_restart,\n",
    "                    add_residual_connection=add_residual_connection,\n",
    "                    bias=bias\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        self.gat_net = nn.Sequential(\n",
    "            GATLayerWithIRCRWR(\n",
    "                num_in_features=num_in_features,  # consequence of concatenation\n",
    "                num_out_features=8,\n",
    "                num_of_heads=8,\n",
    "                gamma=gamma,\n",
    "                beta=beta,\n",
    "                concat=True,\n",
    "                activation=nn.ELU(),\n",
    "                dropout_prob=dropout,\n",
    "                random_walk_with_restart=random_walk_with_restart,\n",
    "                add_residual_connection=add_residual_connection,\n",
    "                bias=bias\n",
    "            ),\n",
    "            *additional_layers,\n",
    "            # GATLayerWithIRCRWR(\n",
    "            #     num_in_features=8 * 8,  # consequence of concatenation\n",
    "            #     num_out_features=num_classes,\n",
    "            #     num_of_heads=1,\n",
    "            #     concat=False,  # last GAT layer does mean avg, the others do concat\n",
    "            #     activation=None,  # last layer just outputs raw scores\n",
    "            #     dropout_prob=dropout,\n",
    "            #     random_walk_with_restart=False,\n",
    "            #     add_residual_connection=False,\n",
    "            #     bias=bias\n",
    "            # )\n",
    "        )\n",
    "\n",
    "    # data is just a (in_nodes_features, edge_index) tuple, I had to do it like this because of the nn.Sequential:\n",
    "    # https://discuss.pytorch.org/t/forward-takes-2-positional-arguments-but-3-were-given-for-nn-sqeuential-with-linear-layers/65698\n",
    "    def forward(self, data):\n",
    "        data = data + (None, None,)\n",
    "        return self.gat_net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.018512724838853595\n",
      "Epoch 10, Loss: 0.008213168471465929\n",
      "Epoch 20, Loss: 0.0063291742885768325\n",
      "Epoch 30, Loss: 0.005307221797273999\n",
      "Epoch 40, Loss: 0.004621482789115364\n",
      "Epoch 50, Loss: 0.004126356173068179\n",
      "Epoch 60, Loss: 0.0037544717609242833\n",
      "Epoch 70, Loss: 0.0034696991062261057\n",
      "Epoch 80, Loss: 0.0032515283223811097\n",
      "Epoch 90, Loss: 0.003133155943571986\n",
      "Epoch 100, Loss: 0.002979471438832024\n",
      "Epoch 110, Loss: 0.0028631433923276884\n",
      "Epoch 120, Loss: 0.0027894047554993147\n",
      "Epoch 130, Loss: 0.002759775544788591\n",
      "Epoch 140, Loss: 0.0027067347216093844\n",
      "Epoch 150, Loss: 0.0027011615028007807\n",
      "Epoch 160, Loss: 0.002669993834160235\n",
      "Epoch 170, Loss: 0.0026495806971002446\n",
      "Epoch 180, Loss: 0.0026039138048317683\n",
      "Epoch 190, Loss: 0.002601569511633307\n",
      "Epoch 200, Loss: 0.0026040874297744367\n",
      "Epoch 210, Loss: 0.002599959687420229\n",
      "Epoch 220, Loss: 0.0025829567533614223\n",
      "Epoch 230, Loss: 0.002621340586260415\n",
      "Epoch 240, Loss: 0.0025759182318717\n",
      "Epoch 250, Loss: 0.002565270755106068\n",
      "Epoch 260, Loss: 0.00257943915391055\n",
      "Epoch 270, Loss: 0.002577701288624012\n",
      "Epoch 280, Loss: 0.0025610371529175328\n",
      "Epoch 290, Loss: 0.0025974803723004688\n",
      "Epoch 300, Loss: 0.002594250445342472\n",
      "Epoch 310, Loss: 0.0025750750509508733\n",
      "Epoch 320, Loss: 0.0025522074031408774\n",
      "Epoch 330, Loss: 0.0025518318991008277\n",
      "Epoch 340, Loss: 0.002546358158031272\n",
      "Epoch 350, Loss: 0.0025846846155100074\n",
      "Epoch 360, Loss: 0.002620938379158419\n",
      "Epoch 370, Loss: 0.0025834656909505737\n",
      "Epoch 380, Loss: 0.002592205968722695\n",
      "Epoch 390, Loss: 0.0025641481539966085\n",
      "Epoch 400, Loss: 0.00255232605672992\n",
      "Epoch 410, Loss: 0.0025435076606007225\n",
      "Epoch 420, Loss: 0.002544120020555113\n",
      "Epoch 430, Loss: 0.0026028314512989005\n",
      "Epoch 440, Loss: 0.002603042293685064\n",
      "Epoch 450, Loss: 0.002570787639569\n",
      "Epoch 460, Loss: 0.002546543490321705\n",
      "Epoch 470, Loss: 0.002549694531927208\n",
      "Epoch 480, Loss: 0.0025345335160052635\n",
      "Epoch 490, Loss: 0.0025260478607445434\n",
      "Epoch 500, Loss: 0.0025456888183262648\n",
      "Epoch 510, Loss: 0.002540188598041012\n",
      "Epoch 520, Loss: 0.0025317849022988242\n",
      "Epoch 530, Loss: 0.0025220456933840547\n",
      "Epoch 540, Loss: 0.0025578486784334615\n",
      "Epoch 550, Loss: 0.0025279477012978553\n",
      "Epoch 560, Loss: 0.0025292071816063926\n",
      "Epoch 570, Loss: 0.0025325321139327895\n",
      "Epoch 580, Loss: 0.0025193069188606475\n",
      "Epoch 590, Loss: 0.0025545788844802885\n",
      "Epoch 600, Loss: 0.002526585933290195\n",
      "Epoch 610, Loss: 0.0025281532337460364\n",
      "Epoch 620, Loss: 0.0025496179139922266\n",
      "Epoch 630, Loss: 0.002515139492371262\n",
      "Epoch 640, Loss: 0.0026439688938063822\n",
      "Epoch 650, Loss: 0.0025716322957941573\n",
      "Epoch 660, Loss: 0.0025403091777985404\n",
      "Epoch 670, Loss: 0.0025172173041062037\n",
      "Epoch 680, Loss: 0.0025316635474077203\n",
      "Epoch 690, Loss: 0.00251900844077699\n",
      "Epoch 700, Loss: 0.0025335810947464477\n",
      "Epoch 710, Loss: 0.0025144406206758503\n",
      "Epoch 720, Loss: 0.0026034676858614695\n",
      "Epoch 730, Loss: 0.0025537445704024372\n",
      "Epoch 740, Loss: 0.002522430220904585\n",
      "Epoch 750, Loss: 0.0025359914960679532\n",
      "Epoch 760, Loss: 0.002516438533703575\n",
      "Epoch 770, Loss: 0.002515442413417432\n",
      "Epoch 780, Loss: 0.002515343091336952\n",
      "Epoch 790, Loss: 0.002517560022950961\n",
      "Epoch 800, Loss: 0.0025242293868600633\n",
      "Epoch 810, Loss: 0.00260250869908613\n",
      "Epoch 820, Loss: 0.0025379200837680528\n",
      "Epoch 830, Loss: 0.002512574632272936\n",
      "Epoch 840, Loss: 0.002607779594996846\n",
      "Epoch 850, Loss: 0.002550468185913117\n",
      "Epoch 860, Loss: 0.0025193299576507207\n",
      "Epoch 870, Loss: 0.0025169926911921855\n",
      "Epoch 880, Loss: 0.0025080761126504976\n",
      "Epoch 890, Loss: 0.002541274920914727\n",
      "Epoch 900, Loss: 0.0025046399950824174\n",
      "Epoch 910, Loss: 0.0025489741351810485\n",
      "Epoch 920, Loss: 0.0025495746909934337\n",
      "Epoch 930, Loss: 0.0025217759991677377\n",
      "Epoch 940, Loss: 0.0025018331253616397\n",
      "Epoch 950, Loss: 0.002649672779414018\n",
      "Epoch 960, Loss: 0.0025820527346209006\n",
      "Epoch 970, Loss: 0.002524848148150155\n",
      "Epoch 980, Loss: 0.00250155057307422\n",
      "Epoch 990, Loss: 0.0025117548659737685\n",
      "tensor([[-0.4185,  0.4433,  0.0692,  ...,  0.0017, -0.0258, -0.0086],\n",
      "        [ 0.4855,  1.2834,  0.1600,  ...,  0.0754, -0.0186,  0.0526],\n",
      "        [-0.3187, -1.2518, -0.0135,  ...,  0.0507,  0.0364,  0.0252],\n",
      "        ...,\n",
      "        [-0.8628,  1.5118, -0.0148,  ...,  0.0017,  0.0082, -0.0051],\n",
      "        [ 0.6992,  0.8542, -0.0188,  ..., -0.0115, -0.0156, -0.0263],\n",
      "        [ 1.6362,  0.9187, -0.0122,  ..., -0.0083, -0.0034, -0.0264]],\n",
      "       device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 그래프 데이터 정의\n",
    "# final_features = torch.tensor(np.load(f'./final_features_without_genres.npy')).to(device)\n",
    "# final_features = torch.tensor(np.load(f'./final_features_without_directors.npy')).to(device)\n",
    "final_features = torch.tensor(np.load(f'./final_features_without_directors_0511.npy')).to(device)\n",
    "# final_features type to double\n",
    "# final_features = final_features.to(torch.double)\n",
    "edge_index = torch.tensor(np.load(f'./directors_edge_index.npy')).to(device) # torch.tensor(np.load(f'./genres_edge_index.npy')).to(device)\n",
    "num_input_features = final_features.shape[1]\n",
    "# 각 노드의 특징을 나타내는 임의의 벡터\n",
    "x = final_features\n",
    "\n",
    "# 그래프 데이터 객체 생성\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "# 모델, 손실 함수, 최적화 알고리즘 초기화\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, feature_size, out_size):\n",
    "        super(GAT, self).__init__()\n",
    "        self.gat1 = GATConv(feature_size, out_size, heads=1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 모델, 손실 함수, 최적화 알고리즘 초기화\n",
    "model = GAT(feature_size=num_input_features, out_size=num_input_features).to(device)\n",
    "model.double()\n",
    "# model = GATWithIRCRWR(num_of_additional_layer=1, num_in_features=num_input_features, gamma=0.7, beta=None, random_walk_with_restart=True, add_residual_connection=False, bias=True, dropout=0.6).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 학습 과정\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = ((out - data.x[:]) ** 2).mean()  # MSE\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# 학습된 노드 임베딩 확인\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4185,  0.4433,  0.0692,  ...,  0.0017, -0.0258, -0.0086],\n",
       "        [ 0.4855,  1.2834,  0.1600,  ...,  0.0754, -0.0186,  0.0526],\n",
       "        [-0.3187, -1.2518, -0.0135,  ...,  0.0507,  0.0364,  0.0252],\n",
       "        ...,\n",
       "        [-0.8628,  1.5118, -0.0148,  ...,  0.0017,  0.0082, -0.0051],\n",
       "        [ 0.6992,  0.8542, -0.0188,  ..., -0.0115, -0.0156, -0.0263],\n",
       "        [ 1.6362,  0.9187, -0.0122,  ..., -0.0083, -0.0034, -0.0264]],\n",
       "       device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6534,  0.2353,  0.0287,  ...,  0.0176,  0.0353, -0.0232],\n",
       "        [ 0.6367,  1.3329,  0.1633,  ...,  0.0743, -0.0190,  0.0559],\n",
       "        [-0.3094, -1.2843, -0.0157,  ...,  0.0528,  0.0359,  0.0256],\n",
       "        ...,\n",
       "        [-0.9974,  0.5730, -0.0165,  ..., -0.0368,  0.0734, -0.1050],\n",
       "        [-2.2876, -0.2712, -0.0148,  ..., -0.0415,  0.0264,  0.0238],\n",
       "        [ 1.7119,  0.9107, -0.0148,  ..., -0.0054, -0.0053, -0.0255]],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save out\n",
    "np.save('embeddings_without_directors_gat_0512.npy', out.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.1+cu111.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
